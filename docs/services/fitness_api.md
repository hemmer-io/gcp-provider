# Fitness_api Service



**Resources**: 4

---

## Overview

The fitness_api service provides access to 4 resource types:

- [Data_source](#data_source) [CRUD]
- [Dataset](#dataset) [CRUD]
- [Session](#session) [RUD]
- [Data_point_change](#data_point_change) [R]

---

## Resources


### Data_source

Creates a new data source that is unique across all data sources belonging to this user. A data source is a unique source of sensor data. Data sources can expose raw data coming from hardware sensors on local or companion devices. They can also expose derived data, created by transforming or merging other data sources. Multiple data sources can exist for the same data type. Every data point in every dataset inserted into or read from the Fitness API has an associated data source. Each data source produces a unique stream of dataset updates, with a unique data source identifier. Not all changes to data source affect the data stream ID, so that data collected by updated versions of the same application/device can still be considered to belong to the same data source. Data sources are identified using a string generated by the server, based on the contents of the source being created. The dataStreamId field should not be set when invoking this method. It will be automatically generated by the server with the correct format. If a dataStreamId is set, it must match the format that the server would generate. This format is a combination of some fields from the data source, and has a specific order. If it doesn't match, the request will fail with an error. Specifying a DataType which is not a known type (beginning with "com.google.") will create a DataSource with a *custom data type*. Custom data types are only readable by the application that created them. Custom data types are *deprecated*; use standard data types instead. In addition to the data source fields included in the data source ID, the developer project number that is authenticated when creating the data source is included. This developer project number is obfuscated when read by any other developer reading public data types.

**Operations**: ✅ Create ✅ Read ✅ Update ✅ Delete

#### Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `data_type` | String |  | The data type defines the schema for a stream of data being collected by, inserted into, or queried from the Fitness API. |
| `device` | String |  | Representation of an integrated device (such as a phone or a wearable) that can hold sensors. |
| `data_quality_standard` | Vec<String> |  | DO NOT POPULATE THIS FIELD. It is never populated in responses from the platform, and is ignored in queries. It will be removed in a future version entirely. |
| `data_stream_id` | String |  | A unique identifier for the data stream produced by this data source. The identifier includes: - The physical device's manufacturer, model, and serial number (UID). - The application's package name or name. Package name is used when the data source was created by an Android application. The developer project number is used when the data source was created by a REST client. - The data source's type. - The data source's stream name. Note that not all attributes of the data source are used as part of the stream identifier. In particular, the version of the hardware/the application isn't used. This allows us to preserve the same stream through version updates. This also means that two DataSource objects may represent the same data stream even if they're not equal. The exact format of the data stream ID created by an Android application is: type:dataType.name:application.packageName:device.manufacturer:device.model:device.uid:dataStreamName The exact format of the data stream ID created by a REST client is: type:dataType.name:developer project number:device.manufacturer:device.model:device.uid:dataStreamName When any of the optional fields that make up the data stream ID are absent, they will be omitted from the data stream ID. The minimum viable data stream ID would be: type:dataType.name:developer project number Finally, the developer project number and device UID are obfuscated when read by any REST or Android client that did not create the data source. Only the data source creator will see the developer project number in clear and normal form. This means a client will see a different set of data_stream_ids than another client with different credentials. |
| `name` | String |  | An end-user visible name for this data source. |
| `type` | String |  | A constant describing the type of this data source. Indicates whether this data source produces raw or derived data. |
| `data_stream_name` | String |  | The stream name uniquely identifies this particular data source among other data sources of the same type from the same underlying producer. Setting the stream name is optional, but should be done whenever an application exposes two streams for the same data type, or when a device has two equivalent sensors. |
| `application` | String |  | Information about an application which feeds sensor data into the platform. |
| `user_id` | String | ✅ | Create the data source for the person identified. Use me to indicate the authenticated user. Only me is supported at this time. |


#### Outputs

| Output | Type | Description |
|--------|------|-------------|
| `data_type` | String | The data type defines the schema for a stream of data being collected by, inserted into, or queried from the Fitness API. |
| `device` | String | Representation of an integrated device (such as a phone or a wearable) that can hold sensors. |
| `data_quality_standard` | Vec<String> | DO NOT POPULATE THIS FIELD. It is never populated in responses from the platform, and is ignored in queries. It will be removed in a future version entirely. |
| `data_stream_id` | String | A unique identifier for the data stream produced by this data source. The identifier includes: - The physical device's manufacturer, model, and serial number (UID). - The application's package name or name. Package name is used when the data source was created by an Android application. The developer project number is used when the data source was created by a REST client. - The data source's type. - The data source's stream name. Note that not all attributes of the data source are used as part of the stream identifier. In particular, the version of the hardware/the application isn't used. This allows us to preserve the same stream through version updates. This also means that two DataSource objects may represent the same data stream even if they're not equal. The exact format of the data stream ID created by an Android application is: type:dataType.name:application.packageName:device.manufacturer:device.model:device.uid:dataStreamName The exact format of the data stream ID created by a REST client is: type:dataType.name:developer project number:device.manufacturer:device.model:device.uid:dataStreamName When any of the optional fields that make up the data stream ID are absent, they will be omitted from the data stream ID. The minimum viable data stream ID would be: type:dataType.name:developer project number Finally, the developer project number and device UID are obfuscated when read by any REST or Android client that did not create the data source. Only the data source creator will see the developer project number in clear and normal form. This means a client will see a different set of data_stream_ids than another client with different credentials. |
| `name` | String | An end-user visible name for this data source. |
| `type` | String | A constant describing the type of this data source. Indicates whether this data source produces raw or derived data. |
| `data_stream_name` | String | The stream name uniquely identifies this particular data source among other data sources of the same type from the same underlying producer. Setting the stream name is optional, but should be done whenever an application exposes two streams for the same data type, or when a device has two equivalent sensors. |
| `application` | String | Information about an application which feeds sensor data into the platform. |


#### Usage Example

```kcl
# main.k
import gcp

# Initialize provider
provider = gcp.GcpProvider {
    project = "my-project-id"
}

# Create data_source
data_source = provider.fitness_api.Data_source {
    user_id = "value"  # Create the data source for the person identified. Use me to indicate the authenticated user. Only me is supported at this time.
}

# Access data_source outputs
data_source_id = data_source.id
data_source_data_type = data_source.data_type
data_source_device = data_source.device
data_source_data_quality_standard = data_source.data_quality_standard
data_source_data_stream_id = data_source.data_stream_id
data_source_name = data_source.name
data_source_type = data_source.type
data_source_data_stream_name = data_source.data_stream_name
data_source_application = data_source.application
```

---


### Dataset

Aggregates data of a certain type or stream into buckets divided by a given type of boundary. Multiple data sets of multiple types and from multiple sources can be aggregated into exactly one bucket type per request.

**Operations**: ✅ Create ✅ Read ✅ Update ✅ Delete

#### Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `end_time_millis` | String |  | The end of a window of time. Data that intersects with this time window will be aggregated. The time is in milliseconds since epoch, inclusive. The maximum allowed difference between start_time_millis // and end_time_millis is 7776000000 (roughly 90 days). |
| `aggregate_by` | Vec<String> |  | The specification of data to be aggregated. At least one aggregateBy spec must be provided. All data that is specified will be aggregated using the same bucketing criteria. There will be one dataset in the response for every aggregateBy spec. |
| `bucket_by_activity_segment` | String |  | Specifies that data be aggregated each activity segment recorded for a user. Similar to bucketByActivitySegment, but bucketing is done for each activity segment rather than all segments of the same type. Mutually exclusive of other bucketing specifications. |
| `bucket_by_time` | String |  | Specifies that data be aggregated by a single time interval. Mutually exclusive of other bucketing specifications. |
| `bucket_by_activity_type` | String |  | Specifies that data be aggregated by the type of activity being performed when the data was recorded. All data that was recorded during a certain activity type (.for the given time range) will be aggregated into the same bucket. Data that was recorded while the user was not active will not be included in the response. Mutually exclusive of other bucketing specifications. |
| `start_time_millis` | String |  | The start of a window of time. Data that intersects with this time window will be aggregated. The time is in milliseconds since epoch, inclusive. |
| `bucket_by_session` | String |  | Specifies that data be aggregated by user sessions. Data that does not fall within the time range of a session will not be included in the response. Mutually exclusive of other bucketing specifications. |
| `filtered_data_quality_standard` | Vec<String> |  | DO NOT POPULATE THIS FIELD. It is ignored. |
| `user_id` | String | ✅ | Aggregate data for the person identified. Use me to indicate the authenticated user. Only me is supported at this time. |


#### Outputs

| Output | Type | Description |
|--------|------|-------------|
| `next_page_token` | String | This token will be set when a dataset is received in response to a GET request and the dataset is too large to be included in a single response. Provide this value in a subsequent GET request to return the next page of data points within this dataset. |
| `data_source_id` | String | The data stream ID of the data source that created the points in this dataset. |
| `max_end_time_ns` | String | The largest end time of all data points in this possibly partial representation of the dataset. Time is in nanoseconds from epoch. This should also match the second part of the dataset identifier. |
| `point` | Vec<String> | A partial list of data points contained in the dataset, ordered by endTimeNanos. This list is considered complete when retrieving a small dataset and partial when patching a dataset or retrieving a dataset that is too large to include in a single response. |
| `min_start_time_ns` | String | The smallest start time of all data points in this possibly partial representation of the dataset. Time is in nanoseconds from epoch. This should also match the first part of the dataset identifier. |


#### Usage Example

```kcl
# main.k
import gcp

# Initialize provider
provider = gcp.GcpProvider {
    project = "my-project-id"
}

# Create dataset
dataset = provider.fitness_api.Dataset {
    user_id = "value"  # Aggregate data for the person identified. Use me to indicate the authenticated user. Only me is supported at this time.
}

# Access dataset outputs
dataset_id = dataset.id
dataset_next_page_token = dataset.next_page_token
dataset_data_source_id = dataset.data_source_id
dataset_max_end_time_ns = dataset.max_end_time_ns
dataset_point = dataset.point
dataset_min_start_time_ns = dataset.min_start_time_ns
```

---


### Session

Lists sessions previously created.

**Operations**: ✅ Read ✅ Update ✅ Delete

#### Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `start_time_millis` | String |  | A start time, in milliseconds since epoch, inclusive. |
| `description` | String |  | A description for this session. |
| `name` | String |  | A human readable name of the session. |
| `modified_time_millis` | String |  | A timestamp that indicates when the session was last modified. |
| `activity_type` | i64 |  | The type of activity this session represents. |
| `application` | String |  | The application that created the session. |
| `active_time_millis` | String |  | Session active time. While start_time_millis and end_time_millis define the full session time, the active time can be shorter and specified by active_time_millis. If the inactive time during the session is known, it should also be inserted via a com.google.activity.segment data point with a STILL activity value |
| `id` | String |  | A client-generated identifier that is unique across all sessions owned by this particular user. |
| `end_time_millis` | String |  | An end time, in milliseconds since epoch, inclusive. |
| `session_id` | String | ✅ | The ID of the session to be created. |
| `user_id` | String | ✅ | Create sessions for the person identified. Use me to indicate the authenticated user. Only me is supported at this time. |


#### Outputs

| Output | Type | Description |
|--------|------|-------------|
| `deleted_session` | Vec<String> | If includeDeleted is set to true in the request, and startTime and endTime are omitted, this will include sessions which were deleted since the last sync. |
| `has_more_data` | bool | Flag to indicate server has more data to transfer. DO NOT USE THIS FIELD. It is never populated in responses from the server. |
| `next_page_token` | String | The sync token which is used to sync further changes. This will only be provided if both startTime and endTime are omitted from the request. |
| `session` | Vec<String> | Sessions starting before endTime of the request and ending after startTime of the request up to (endTime of the request + 1 day). |


#### Usage Example

```kcl
# main.k
import gcp

# Initialize provider
provider = gcp.GcpProvider {
    project = "my-project-id"
}

# Access session outputs
session_id = session.id
session_deleted_session = session.deleted_session
session_has_more_data = session.has_more_data
session_next_page_token = session.next_page_token
session_session = session.session
```

---


### Data_point_change

Queries for user's data point changes for a particular data source.

**Operations**: ✅ Read

#### Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|


#### Outputs

| Output | Type | Description |
|--------|------|-------------|
| `deleted_data_point` | Vec<String> | Deleted data points for the user. Note, for modifications this should be parsed before handling insertions. |
| `inserted_data_point` | Vec<String> | Inserted data points for the user. |
| `next_page_token` | String | The continuation token, which is used to page through large result sets. Provide this value in a subsequent request to return the next page of results. |
| `data_source_id` | String | The data stream ID of the data source with data point changes. |


#### Usage Example

```kcl
# main.k
import gcp

# Initialize provider
provider = gcp.GcpProvider {
    project = "my-project-id"
}

# Access data_point_change outputs
data_point_change_id = data_point_change.id
data_point_change_deleted_data_point = data_point_change.deleted_data_point
data_point_change_inserted_data_point = data_point_change.inserted_data_point
data_point_change_next_page_token = data_point_change.next_page_token
data_point_change_data_source_id = data_point_change.data_source_id
```

---



## Common Operations

### Creating Multiple Resources

```kcl
import gcp

provider = gcp.GcpProvider {
    project = "my-project-id"
}

# Create multiple data_source resources
data_source_0 = provider.fitness_api.Data_source {
    user_id = "value-0"
}
data_source_1 = provider.fitness_api.Data_source {
    user_id = "value-1"
}
data_source_2 = provider.fitness_api.Data_source {
    user_id = "value-2"
}
```

### Conditional Creation

```kcl
# Only create in production
if environment == "production":
    data_source = provider.fitness_api.Data_source {
        user_id = "production-value"
    }
```

---

## Related Documentation

- [GCP Fitness_api Documentation](https://cloud.google.com/fitness_api/docs)
- [Getting Started Guide](../getting-started.md)
- [Installation Guide](../installation.md)
- ⬅️ [Back to README](../../README.md)
